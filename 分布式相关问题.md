### Redis为什么不能使用大key

Redis内存浪费严重，当内存达到一定程度，就会频繁触发LRU清除，从而导致缓存穿透问题

集群倾斜严重，负载不均衡，假设都通过hash函数来算对应的key应该存放在哪个数据节点，这时候有些Key大会导致Redis所承载的数据容量不一致进而导致Redis的qps能力不一致。

由于Redis是处理命令是通过单线程的方式处理的，所以一旦有多个大key就会造成客户端指令挤压严重

优化思路:

对大key数据进行裁减

业务进行调优，减少Set长度

开启Redis客户端缓存（Redis以前是要进行双写同步的，现在Redis60及以上只要发现数据不一致通过监听以及事件机制就能够告知本地进行本地缓存修改）

定时扫描及时发现大key，手动清理（通过rdb_bigkeys）



### 解决Redis集群的脑裂问题

Redis集群的感知是通过sentinel集群来控制的，当发生网络阻塞或处理数据不及时，就会造成master出现无法响应ack包给sentinel集群，这时候sentinnel集群认为master已经挂掉了，就会出现sentinel集群重新选举master，而客户端还是往旧master中发送数据，这时候就产生了脑裂问题。当旧master发送ack包给sentinel集群的时候，就会将旧master变成slave，主从架构的Redis，一开始slave节点会清空所有数据然后将主节点通过bgsave全部数据备份到slave，最后才是master增量复制到slave，所以脑裂问题闹成的是数据丢失问题。

Redis主要有两个参数来减少数据丢失问题

min-slaves-to-write x 

master必须拥有x个slave节点

min-slaves-max-lag x

要求主从同步延时时间不超过x秒

只要这两个条件都不满足，旧会使得master与客户端断开连接min-slaves-max-lag x设置的时间可以保证数据尽可能少丢失。



### 哈希一致性

一开始互联的架构是偏向于单体架构，这时候使用数据库可以直接使用表中的主键，但是随着业务量的增多，数据库随着数据增多造成性能严重降低，所以就有了分库分表的方式。而分库分表的过程中再次遇到了需要对数据库进行扩容操作的时候就非常头痛，因为符合hash规则，必须将数据进行大规模迁移，哈希一致性应运而生。

hash函数的规则可以是通过IP地址、节点名称，对应区域等来作为参数

哈希一致性的是通过一个足够大的空间来去映射对应的数据库，通过访问某一个数据进行hash运算得到数据应该数据节点的位置，然后如果当前没有数据库，就去数据顺移到下一个数据库，当然，这会出现数据头重脚轻等问题。所以引入了虚拟数据库节点，把数据更加均匀的分散到数据库中，只要是映射到数据库虚拟节点，就会往对应的物理数据库发送数据。

上环数据就需要将原本顺移到该数据库的顺移到新数据库

但是需要注意的是，上环操作需要停止服务，上环完毕，数据成功对接才能够启动服务，继续对外通过服务

面对的问题：

上环分布的hash算法需要自己完成或者使用Google开源的CityHash

对数据进行迁移的组件目前没有，需要自己写程序实现规则迁移

集群节点不固定，要求增加牵制代理（ShardingProxy、 ProxySQL）屏蔽数据访问细节，且路由规则允许灵活调整。



### 分布式事务



#### TCC

TCC属于2阶段分布式事务

TCC是Try，Confirm，Cancel  -尝试确认取消

Try尝试阶段，对资源进行锁定

Confirm确认阶段，对资源进行确认，完成操作

Cancel取消阶段，对资源进行还原，取消操作

方法：

通过在数据表中增加字段来解决

比如说

我买了可乐10瓶，花了我账户的30块钱

现在分成两个服务，一个是库存服务，一个是用户服务。

我需要在库存服务中冻结10瓶可乐，同时也需要在用户服务中把我的账户扣出30块钱并且冻结30块钱，状态设置为初始态。

如果没有问题，那么用户服务中账户余额就不用管，把冻结金额自动扣除，并把状态设置为完成；库存服务就直接减掉10瓶可乐。

如果出现网络堵塞或者数据库宕机等无法对资源进行统一的情况下，就对资源进行取消，把用户服务中冻结的金额回归到账户余额上，然后状态设置为取消，接着再把库存服务中冻结的10瓶可乐回归到可乐总库存中。



### 消息队列中的常见问题

#### 重复消费问题

如何保证消息不会被重复消费

##### 分析原因

生产者：由于网络延时问题或服务器本身压力大造成超时,没有收到MQ中的应答信号，这时候就会产生多发的消息。

MQ：消费者消费完消息后，如果消费者在发送ACK信号的时候MQ挂了，重启服务后MQ会再次推送该消息，导致重复消费。

消费者：正要往MQ发送ACK消息的时候消费者挂掉了，这时候消费者已经接收到了数据但是没有发送ACK，消费服务重启后MQ认为消费者没有消费这条消息，就会再次推送该消息。

##### 处理重复消费

如果该消息是幂等性的，那么无论怎么样重复消费都不会对数据本身造成影响

如果消息不是幂等的，就需要每条消息都带一个唯一的消息id，如果查询出来的数据与消息id不一致，说明没有消费过，这样就能够写入数据。

现在大多情况下为了保证高并发，大多都会使用Redis来存全局消息id，然后value对应的是数据本身。



#### 消息丢失问题

##### 分析原因

消息丢失可能在生产者、MQ、以及消费者的任何一环上。

生产者而言，网络抖动，网络超时，导致消息在网络中丢失了，再次发送数据的时候MQ内部出现问题导致消息丢失。

MQ而言，内部出现了错误，导致消息丢失。比如MQ挂掉了，但是有消息没有推送给消费者也没有落盘，重启服务后就会丢失消息。

消费者而言，如果采用的是异步方式，收到消息但是还没有对消息进行处理，这时候发送ACK信号给MQ，这时候MQ就不再发送数据给消费者。此时收到消息且发送ACK信号给MQ后，如果消费者挂了，这时候就会产生消息丢失问题。

##### 保证消息可靠性

生产者生产消息阶段，确保生产者与MQ进行点对点的可靠性传输，这与TCP/IP里ACK机制相似。

MQ存储完毕才发送消息（保证MQ宕机生产者重发），同理消费者消费完消息后才发送ACK给消息队列（保证消费者宕机MQ重发）。

#### 消息顺序问题

多线程语义下，消息是乱序执行的，让消息有序就成为了悖论。

消息顺序执行的前提是消息不丢失。

消息的顺序性不仅仅要靠MQ本身来保证，还需要生产者消费者共同保证。



#### 消息延迟问题

延迟消息队列是MQ对于生产消息方生产消息速率和消费者消费方效率不一致问题而提出的解决方案，从而在最大情况下尽量减少消费端丢失数据以及消息积压在MQ中。

消息的延迟指的是消费端消费消息的延迟。这里就涉及到消息队列的消费模型push和pull，一个是靠MQ去push消息到消费者，一个靠消费者去主动往MQ进行pull消息。

push模型是关注消息的实时性，但是一旦消费端消费消息的能力赶不上生产端的时候就会造成消费端不断有数据过来，缓存已满，而消费端无法应付，导致系统产生错误或丢失数据的风险。

pull模型是关注自主可控的拉取消息，但是消费者何时进行pull操作不可知，pull事件间隔短，一段时间内MQ没有可消费的消息，就会产生无效的pull请求，增大网络开销。而pull的时间间隔久，如果MQ积压了很多消息，就会导致消费者处理消费的压力不断上升、如果设置了过期时间，那么就可能已经超过了消费时间、持续积压造成MQ消息数量达到上限，这时就会丢弃生产者生产的消息。